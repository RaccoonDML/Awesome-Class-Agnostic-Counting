# Awesome Crowd Counting: note
【腾讯文档】SICC-Survey   https://docs.qq.com/sheet/DT3BlU3RrUmpvSklo?tab=BB08J2
![image](https://user-images.githubusercontent.com/49635872/221356691-de7884b9-fe26-4ffb-be4f-5787f519f71a.png)

(Paper list is from [awesome-crowd-counting](https://github.com/gjy3035/Awesome-Crowd-Counting))

# Awesome-Class-Agnostic-Counting

Paper list and performance comparison for **CAC** (Class Agnostic Counting)



## Papers (latest first)
- **[LOCA]** A Low-Shot Object Counting Network With Iterative Prototype Adaptation [[paper]](https://arxiv.org/pdf/2211.08217v1.pdf)
- **[SPDCN, BMVC22]** Scale-Prior Deformable Convolution for Exemplar-Guided Class-Agnostic Counting [[paper]](https://bmvc2022.mpi-inf.mpg.de/0313.pdf)
- **[CounTR, BMVC22]** CounTR: Transformer-based Generalised Visual Counting [[paper]](https://arxiv.org/pdf/2208.13721.pdf)
- **[RCC]** Learning to Count Anything: Reference-less Class-agnostic Counting with Weak Supervision [[paper]](https://arxiv.org/pdf/2205.10203.pdf) [[code]](https://github.com/ActiveVisionLab/LearningToCountAnything)
- **[RepRPN-Counter]** Exemplar Free Class Agnostic Counting [[paper]](https://arxiv.org/pdf/2205.14212.pdf) (Ranjan)
- **[SAFECount, WACV23]** Few-shot Object Counting with Similarity-Aware Feature Enhancement [[paper]](https://arxiv.org/pdf/2201.08959.pdf)
- **[Counting-DETR, ECCV22]** Few-shot Object Counting and Detection [[paper]](https://arxiv.org/pdf/2207.10988v2.pdf)
- **[LaoNet]** OBJECT COUNTING: YOU ONLY NEED TO LOOK AT ONE [[paper]](https://arxiv.org/pdf/2112.05993.pdf)
- **[BMNet, CVPR22]** Represent, Compare, and Learn: A Similarity-Aware Framework for Class-Agnostic Counting [[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_Represent_Compare_and_Learn_A_Similarity-Aware_Framework_for_Class-Agnostic_Counting_CVPR_2022_paper.pdf) [[code]](https://github.com/flyinglynx/Bilinear-Matching-Network)
- **[VCN, CVPRW22]** Vicinal Counting Networks [[paper]](https://openaccess.thecvf.com/content/CVPR2022W/L3D-IVU/papers/Ranjan_Vicinal_Counting_Networks_CVPRW_2022_paper.pdf) (Ranjan)
- **[FamNet, CVPR21]** Learning To Count Everything [[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Ranjan_Learning_To_Count_Everything_CVPR_2021_paper.pdf) [[code]](https://github.com/cvlab-stonybrook/LearningToCountEverything) (Ranjan)
- **[CFOCNet, WACV21]** Class-agnostic Few-shot Object Counting [[paper]](https://openaccess.thecvf.com/content/WACV2021/papers/Yang_Class-Agnostic_Few-Shot_Object_Counting_WACV_2021_paper.pdf)
- **[GMN, ACCV18]** Class-Agnostic Counting [[paper]](https://arxiv.org/pdf/1811.00472.pdf)

## Experiment Comparison (latest last)
[[comparison in notion]](https://sprinkle-fine-c22.notion.site/CAC-e2bb6a6456d849e397aa730705ca6c51)
